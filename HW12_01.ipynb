{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0dba6fc-a6b2-472f-af97-061fafdd6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Last ned og last Fashion-MNIST-datasettet\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5abd18f4-f18a-4624-9c9f-b88824099a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser bildedataene til å være mellom 0 og 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d078e7e-bec4-45a4-a20f-ee24db4bc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatt ut bildene\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abb3337f-e36a-4c0d-978d-8ba040dbcde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d167215a-5911-4ac3-82fd-d2eafb125496",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0c93211-d04a-48dd-af82-3f4067de3e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.6174 - loss: 2.5839 - val_accuracy: 0.8333 - val_loss: 1.8595\n",
      "Epoch 2/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.8266 - loss: 1.8210 - val_accuracy: 0.8675 - val_loss: 1.6391\n",
      "Epoch 3/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.8441 - loss: 1.6705 - val_accuracy: 0.8777 - val_loss: 1.5192\n",
      "Epoch 4/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.8624 - loss: 1.5507 - val_accuracy: 0.8881 - val_loss: 1.4160\n",
      "Epoch 5/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.8696 - loss: 1.4469 - val_accuracy: 0.8915 - val_loss: 1.3321\n",
      "Epoch 6/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.8782 - loss: 1.3611 - val_accuracy: 0.8987 - val_loss: 1.2501\n",
      "Epoch 7/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.8816 - loss: 1.2844 - val_accuracy: 0.8946 - val_loss: 1.2019\n",
      "Epoch 8/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.8854 - loss: 1.2186 - val_accuracy: 0.9018 - val_loss: 1.1226\n",
      "Epoch 9/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.8910 - loss: 1.1504 - val_accuracy: 0.9101 - val_loss: 1.0556\n",
      "Epoch 10/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.8946 - loss: 1.0895 - val_accuracy: 0.9148 - val_loss: 1.0015\n",
      "Epoch 11/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.8970 - loss: 1.0399 - val_accuracy: 0.9148 - val_loss: 0.9565\n",
      "Epoch 12/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9000 - loss: 0.9917 - val_accuracy: 0.9217 - val_loss: 0.9050\n",
      "Epoch 13/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9058 - loss: 0.9388 - val_accuracy: 0.9163 - val_loss: 0.8743\n",
      "Epoch 14/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9063 - loss: 0.9027 - val_accuracy: 0.9262 - val_loss: 0.8261\n",
      "Epoch 15/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9107 - loss: 0.8647 - val_accuracy: 0.9256 - val_loss: 0.7938\n",
      "Epoch 16/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9116 - loss: 0.8314 - val_accuracy: 0.9276 - val_loss: 0.7659\n",
      "Epoch 17/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9121 - loss: 0.8057 - val_accuracy: 0.9303 - val_loss: 0.7329\n",
      "Epoch 18/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9145 - loss: 0.7714 - val_accuracy: 0.9306 - val_loss: 0.7097\n",
      "Epoch 19/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9196 - loss: 0.7392 - val_accuracy: 0.9303 - val_loss: 0.6903\n",
      "Epoch 20/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9205 - loss: 0.7160 - val_accuracy: 0.9406 - val_loss: 0.6538\n",
      "Epoch 21/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9217 - loss: 0.6899 - val_accuracy: 0.9378 - val_loss: 0.6402\n",
      "Epoch 22/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9258 - loss: 0.6642 - val_accuracy: 0.9373 - val_loss: 0.6156\n",
      "Epoch 23/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9215 - loss: 0.6566 - val_accuracy: 0.9380 - val_loss: 0.6042\n",
      "Epoch 24/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9259 - loss: 0.6343 - val_accuracy: 0.9434 - val_loss: 0.5750\n",
      "Epoch 25/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9307 - loss: 0.6073 - val_accuracy: 0.9445 - val_loss: 0.5611\n",
      "Epoch 26/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9279 - loss: 0.5988 - val_accuracy: 0.9470 - val_loss: 0.5412\n",
      "Epoch 27/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9329 - loss: 0.5747 - val_accuracy: 0.9450 - val_loss: 0.5330\n",
      "Epoch 28/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9347 - loss: 0.5577 - val_accuracy: 0.9464 - val_loss: 0.5184\n",
      "Epoch 29/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9341 - loss: 0.5484 - val_accuracy: 0.9507 - val_loss: 0.5009\n",
      "Epoch 30/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9336 - loss: 0.5385 - val_accuracy: 0.9429 - val_loss: 0.5077\n",
      "Epoch 31/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9347 - loss: 0.5249 - val_accuracy: 0.9465 - val_loss: 0.4825\n",
      "Epoch 32/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9393 - loss: 0.5044 - val_accuracy: 0.9477 - val_loss: 0.4741\n",
      "Epoch 33/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9361 - loss: 0.4991 - val_accuracy: 0.9550 - val_loss: 0.4484\n",
      "Epoch 34/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9394 - loss: 0.4904 - val_accuracy: 0.9560 - val_loss: 0.4394\n",
      "Epoch 35/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9397 - loss: 0.4777 - val_accuracy: 0.9490 - val_loss: 0.4421\n",
      "Epoch 36/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9447 - loss: 0.4589 - val_accuracy: 0.9551 - val_loss: 0.4238\n",
      "Epoch 37/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9411 - loss: 0.4615 - val_accuracy: 0.9529 - val_loss: 0.4227\n",
      "Epoch 38/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9447 - loss: 0.4421 - val_accuracy: 0.9420 - val_loss: 0.4347\n",
      "Epoch 39/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9453 - loss: 0.4310 - val_accuracy: 0.9540 - val_loss: 0.4027\n",
      "Epoch 40/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9426 - loss: 0.4320 - val_accuracy: 0.9574 - val_loss: 0.3886\n",
      "Epoch 41/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9495 - loss: 0.4129 - val_accuracy: 0.9611 - val_loss: 0.3782\n",
      "Epoch 42/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9495 - loss: 0.4033 - val_accuracy: 0.9462 - val_loss: 0.4009\n",
      "Epoch 43/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9455 - loss: 0.4042 - val_accuracy: 0.9588 - val_loss: 0.3656\n",
      "Epoch 44/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9475 - loss: 0.3987 - val_accuracy: 0.9582 - val_loss: 0.3682\n",
      "Epoch 45/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9480 - loss: 0.3906 - val_accuracy: 0.9503 - val_loss: 0.3711\n",
      "Epoch 46/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9486 - loss: 0.3809 - val_accuracy: 0.9594 - val_loss: 0.3528\n",
      "Epoch 47/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9518 - loss: 0.3733 - val_accuracy: 0.9594 - val_loss: 0.3458\n",
      "Epoch 48/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9505 - loss: 0.3694 - val_accuracy: 0.9577 - val_loss: 0.3414\n",
      "Epoch 49/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9463 - loss: 0.3741 - val_accuracy: 0.9621 - val_loss: 0.3289\n",
      "Epoch 50/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.9484 - loss: 0.3651 - val_accuracy: 0.9574 - val_loss: 0.3374\n",
      "Epoch 51/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9538 - loss: 0.3458 - val_accuracy: 0.9632 - val_loss: 0.3196\n",
      "Epoch 52/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9508 - loss: 0.3515 - val_accuracy: 0.9582 - val_loss: 0.3225\n",
      "Epoch 53/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9531 - loss: 0.3421 - val_accuracy: 0.9648 - val_loss: 0.3093\n",
      "Epoch 54/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9526 - loss: 0.3382 - val_accuracy: 0.9605 - val_loss: 0.3180\n",
      "Epoch 55/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9508 - loss: 0.3387 - val_accuracy: 0.9624 - val_loss: 0.3062\n",
      "Epoch 56/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9506 - loss: 0.3359 - val_accuracy: 0.9691 - val_loss: 0.2879\n",
      "Epoch 57/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9498 - loss: 0.3333 - val_accuracy: 0.9638 - val_loss: 0.2933\n",
      "Epoch 58/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9516 - loss: 0.3288 - val_accuracy: 0.9668 - val_loss: 0.2862\n",
      "Epoch 59/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9540 - loss: 0.3140 - val_accuracy: 0.9656 - val_loss: 0.2863\n",
      "Epoch 60/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9571 - loss: 0.3071 - val_accuracy: 0.9702 - val_loss: 0.2731\n",
      "Epoch 61/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9554 - loss: 0.3063 - val_accuracy: 0.9628 - val_loss: 0.2817\n",
      "Epoch 62/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9565 - loss: 0.3048 - val_accuracy: 0.9687 - val_loss: 0.2719\n",
      "Epoch 63/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9545 - loss: 0.3048 - val_accuracy: 0.9594 - val_loss: 0.2867\n",
      "Epoch 64/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9531 - loss: 0.3056 - val_accuracy: 0.9670 - val_loss: 0.2679\n",
      "Epoch 65/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9591 - loss: 0.2888 - val_accuracy: 0.9722 - val_loss: 0.2515\n",
      "Epoch 66/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9594 - loss: 0.2842 - val_accuracy: 0.9528 - val_loss: 0.2979\n",
      "Epoch 67/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9567 - loss: 0.2872 - val_accuracy: 0.9663 - val_loss: 0.2572\n",
      "Epoch 68/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9592 - loss: 0.2773 - val_accuracy: 0.9779 - val_loss: 0.2342\n",
      "Epoch 69/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9614 - loss: 0.2710 - val_accuracy: 0.9695 - val_loss: 0.2497\n",
      "Epoch 70/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9574 - loss: 0.2800 - val_accuracy: 0.9612 - val_loss: 0.2664\n",
      "Epoch 71/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9560 - loss: 0.2790 - val_accuracy: 0.9727 - val_loss: 0.2374\n",
      "Epoch 72/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9573 - loss: 0.2757 - val_accuracy: 0.9596 - val_loss: 0.2661\n",
      "Epoch 73/100\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9577 - loss: 0.2724 - val_accuracy: 0.9634 - val_loss: 0.2522\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8924 - loss: 0.5517\n",
      "Test Loss: 0.5521238446235657, Test Accuracy: 0.8944000005722046\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Evaluation Accuracy: 0.8944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Define modell\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001), input_shape=(784,), kernel_initializer=HeNormal()),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001), kernel_initializer=HeNormal()),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001), kernel_initializer=HeNormal()),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='softmax', kernel_initializer=HeNormal()),\n",
    "])\n",
    "\n",
    "# Early stopping\n",
    "def run_experiment_with_early_stopping(model, loss_recording_list, lr=0.0001, x_train=None, y_train=None, val_x=None, val_y=None, epochs=100, patience=5):\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=184,\n",
    "        validation_data=(val_x, val_y),\n",
    "        callbacks=[early_stopping, tensorboard_callback]\n",
    "    )\n",
    "    \n",
    "    # Record the losses\n",
    "    loss_recording_list.append({\n",
    "        'train_loss': history.history['loss'],\n",
    "        'val_loss': history.history['val_loss']\n",
    "    })\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    evaluate(y_test, predictions)\n",
    "\n",
    "# Dummy evaluate function for demonstration\n",
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"Evaluation Accuracy: {accuracy}\")\n",
    "\n",
    "# List to record losses\n",
    "loss_recording_list = []\n",
    "\n",
    "# Run the experiment\n",
    "run_experiment_with_early_stopping_keras(\n",
    "    model=model,\n",
    "    loss_recording_list=loss_recording_list,\n",
    "    lr=0.0001,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    val_x=x_val,\n",
    "    val_y=y_val,\n",
    "    epochs=100,\n",
    "    patience=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
